{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "my-object_detection_tutorial.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varat7v2/PERSON-DETECTION-TRAINING/blob/master/my_object_detection_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8-yl-s-WKMG"
      },
      "source": [
        "# Object Detection API Demo\n",
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.sandbox.google.com/github/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</td></table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rntU14w9QL8Y"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIqbQkC6207g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQsOO72KkDAg"
      },
      "source": [
        "#### Import tensorflow with specific version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HnBjiyJkHAv"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qSGHJCHRv88"
      },
      "source": [
        "Go to tf-model/research/ folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TNBjkQ2R6UF"
      },
      "source": [
        "%cd ~\n",
        "%cd ..\n",
        "%cd /content/drive/My Drive/Colab Notebooks/tf-model/research"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3_Hcsw6VjH8"
      },
      "source": [
        "### Run setup file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_h-aOPJViZM"
      },
      "source": [
        "!python setup.py build\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M69K97UtL0T"
      },
      "source": [
        "#### Running setup file for /research/slim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0UAWbOJsxxc"
      },
      "source": [
        "%cd slim\n",
        "!python setup.py build\n",
        "!python setup.py install\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTTknhTwWoGC"
      },
      "source": [
        "#### Compile protobufs and install the object_detection package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d55X5omaWvqZ"
      },
      "source": [
        "!pwd\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqP5z3lsWyyR"
      },
      "source": [
        "#### Add Libraries to PYTHONPATH\n",
        "/content/drive/My Drive/Colab Notebooks/tf-model/research"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3AtyIVVXR-4"
      },
      "source": [
        "!pwd\n",
        "!export PYTHONPATH=$PYTHONPATH:\"/content/drive/My Drive/Colab Notebooks/tf-model/research\":\"/content/drive/My Drive/Colab Notebooks/tf-model/research/slim\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QutseFL-jnY1"
      },
      "source": [
        "#### Test that you have correctly installed the Tensorflow Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY2KcoGCjwEg"
      },
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VliNOLKvubRG"
      },
      "source": [
        "### Training the model using OD API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUkY9TxMufQ_"
      },
      "source": [
        "#  !python object_detection/legacy/train.py \\\n",
        "#  --clone_on_cpu=False --logtostderr \\\n",
        "#  --train_dir=/content/drive/My\\ Drive/Colab\\ Notebooks/ssdlite_checkpoints/ssd_mobilenet_v2_150x150_32f \\\n",
        "#  --pipeline_config_path=/content/drive/My\\ Drive/Colab\\ Notebooks/ssdlite_checkpoints/ssd_mobilenet_v2_150x150_32f/ssd_mobilenet_v2_150x150_32f_colab.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2drSbB-QmaX"
      },
      "source": [
        "Training --> PERSON DETECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2FIq8ThQpq0"
      },
      "source": [
        "!python object_detection/legacy/train.py \\\n",
        "--logtostderr --clone_on_cpu=False \\\n",
        "--train_dir=/content/drive/My\\ Drive/Colab\\ Notebooks/person_detection_train/training/ckpt \\\n",
        "--pipeline_config_path=/content/drive/My\\ Drive/Colab\\ Notebooks/person_detection_train/training/person_detection_colab.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ0Bdkvz64Zj"
      },
      "source": [
        "### Running the tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWTjrDCA69st"
      },
      "source": [
        "# !tensorboard --logdir /content/drive/My Drive/Colab Notebooks/ssdlite_checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBdjK2G5ywuc"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV4P5gyTWKMI"
      },
      "source": [
        "# import numpy as np\n",
        "# import os\n",
        "# import six.moves.urllib as urllib\n",
        "# import sys\n",
        "# import tarfile\n",
        "# import zipfile\n",
        "# import os\n",
        "# import pathlib\n",
        "\n",
        "# from collections import defaultdict\n",
        "# from io import StringIO\n",
        "# from matplotlib import pyplot as plt\n",
        "# from PIL import Image\n",
        "# from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5FNuiRPWKMN"
      },
      "source": [
        "Import the object detection module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-IMl4b6BdGO"
      },
      "source": [
        "# from object_detection.utils import ops as utils_ops\n",
        "# from object_detection.utils import label_map_util\n",
        "# from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYPCiag2iz_q"
      },
      "source": [
        "Patches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF-YlMl8c_bM"
      },
      "source": [
        "# # patch tf1 into `utils.ops`\n",
        "# utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# # Patch the location of gfile\n",
        "# tf.gfile = tf.io.gfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfn_tRFOWKMO"
      },
      "source": [
        "# Model preparation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_sEBLpVWKMQ"
      },
      "source": [
        "## Variables\n",
        "\n",
        "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing the path.\n",
        "\n",
        "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ai8pLZZWKMS"
      },
      "source": [
        "## Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm8xp-0eoItE"
      },
      "source": [
        "# def load_model(model_name):\n",
        "#   base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "#   model_file = model_name + '.tar.gz'\n",
        "#   model_dir = tf.keras.utils.get_file(\n",
        "#     fname=model_name, \n",
        "#     origin=base_url + model_file,\n",
        "#     untar=True)\n",
        "\n",
        "#   model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
        "\n",
        "#   model = tf.saved_model.load(str(model_dir))\n",
        "#   model = model.signatures['serving_default']\n",
        "\n",
        "#   return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1MVVTcLWKMW"
      },
      "source": [
        "## Loading label map\n",
        "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDbpHkiWWKMX"
      },
      "source": [
        "# # List of the strings that is used to add correct label for each box.\n",
        "# PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "# category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVU3U_J6IJVb"
      },
      "source": [
        "For the sake of simplicity we will test on 2 images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG-zn5ykWKMd"
      },
      "source": [
        "# # If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "# PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images')\n",
        "# TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
        "# TEST_IMAGE_PATHS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0_1AGhrWKMc"
      },
      "source": [
        "# Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7aOtOlebK7h"
      },
      "source": [
        "Load an object detection model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XNT0wxybKR6"
      },
      "source": [
        "# model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "# detection_model = load_model(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN1AYfAEJIGp"
      },
      "source": [
        "Check the model's input signature, it expects a batch of 3-color images of type uint8: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK4cnry6wsHY"
      },
      "source": [
        "# print(detection_model.inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8u3BjpMJXZF"
      },
      "source": [
        "And retuns several outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLSZpfaYwuSk"
      },
      "source": [
        "# detection_model.output_dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZyKUJeuxvpT"
      },
      "source": [
        "# detection_model.output_shapes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP5qZ7sXJpwG"
      },
      "source": [
        "Add a wrapper function to call the model, and cleanup the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajmR_exWyN76"
      },
      "source": [
        "# def run_inference_for_single_image(model, image):\n",
        "#   image = np.asarray(image)\n",
        "#   # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "#   input_tensor = tf.convert_to_tensor(image)\n",
        "#   # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "#   input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "#   # Run inference\n",
        "#   output_dict = model(input_tensor)\n",
        "\n",
        "#   # All outputs are batches tensors.\n",
        "#   # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "#   # We're only interested in the first num_detections.\n",
        "#   num_detections = int(output_dict.pop('num_detections'))\n",
        "#   output_dict = {key:value[0, :num_detections].numpy() \n",
        "#                  for key,value in output_dict.items()}\n",
        "#   output_dict['num_detections'] = num_detections\n",
        "\n",
        "#   # detection_classes should be ints.\n",
        "#   output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "#   # Handle models with masks:\n",
        "#   if 'detection_masks' in output_dict:\n",
        "#     # Reframe the the bbox mask to the image size.\n",
        "#     detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "#               output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "#                image.shape[0], image.shape[1])      \n",
        "#     detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "#                                        tf.uint8)\n",
        "#     output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "#   return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1wq0LVyMRR_"
      },
      "source": [
        "Run it on each test image and show the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWh_1zz6aqxs"
      },
      "source": [
        "# def show_inference(model, image_path):\n",
        "#   # the array based representation of the image will be used later in order to prepare the\n",
        "#   # result image with boxes and labels on it.\n",
        "#   image_np = np.array(Image.open(image_path))\n",
        "#   # Actual detection.\n",
        "#   output_dict = run_inference_for_single_image(model, image_np)\n",
        "#   # Visualization of the results of a detection.\n",
        "#   vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "#       image_np,\n",
        "#       output_dict['detection_boxes'],\n",
        "#       output_dict['detection_classes'],\n",
        "#       output_dict['detection_scores'],\n",
        "#       category_index,\n",
        "#       instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "#       use_normalized_coordinates=True,\n",
        "#       line_thickness=4)\n",
        "\n",
        "#   display(Image.fromarray(image_np))\n",
        "#   return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a5wMHN8WKMh"
      },
      "source": [
        "# for image_path in TEST_IMAGE_PATHS:\n",
        "#   output = (show_inference(detection_model, image_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LCwnik3_QEI8"
      },
      "source": [
        "# # idx = output['detection_scores'].argmax()\n",
        "# # print(output['detection_scores'][idx])\n",
        "# # output['detection_boxes'][idx]\n",
        "# import matplotlib.patches as patches\n",
        "# import tkinter\n",
        "# num_objs = 0\n",
        "# cords = []\n",
        "\n",
        "# # print(output['detection_scores'])\n",
        "# for i in range(output['detection_scores'].shape[0]):\n",
        "#     if output['detection_scores'][i] > 0.6:\n",
        "#         cords.append(output['detection_boxes'][i])\n",
        "#         num_objs += 1\n",
        "# print(num_objs)\n",
        "# print(cords[0])\n",
        "# print(cords[1])\n",
        "\n",
        "# # # Create figure and axes\n",
        "# # fig,ax = plt.subplots(1)\n",
        "# # im = np.array(Image.open('models/research/object_detection/test_images/image3.jpg'), dtype=np.uint8)\n",
        "# # # Display the image\n",
        "# # ax.imshow(im)\n",
        "\n",
        "# # # Create a Rectangle patch\n",
        "# # rect = patches.Rectangle((cords[0][0]*255,cords[0][1]*255),height*255,width*255,linewidth=1,edgecolor='r',facecolor='none')\n",
        "# # # Add the patch to the Axes\n",
        "# # ax.add_patch(rect)\n",
        "\n",
        "# # plt.savefig('foo.png')\n",
        "\n",
        "# # # # plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOlxcylWQEJE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsspMPX3Cssg"
      },
      "source": [
        "## Instance Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzkVv_n2MxKC"
      },
      "source": [
        "# model_name = \"mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\"\n",
        "# masking_model = load_model(\"mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S7aZi8ZOhVV"
      },
      "source": [
        "The instance segmentation model includes a `detection_masks` output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ2Sj2VIOZLA"
      },
      "source": [
        "# masking_model.output_shapes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS57rZlnNL7W"
      },
      "source": [
        "# for image_path in TEST_IMAGE_PATHS:\n",
        "#   show_inference(masking_model, image_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}